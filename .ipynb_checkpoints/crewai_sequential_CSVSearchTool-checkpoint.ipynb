{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexfazio/crewAI-quickstart/blob/main/crewai_sequential_CSVSearchTool_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANCxcFs-qVl4"
   },
   "source": [
    "# crewai-sequential-CSVSearchTool\n",
    "\n",
    "üìÇ Github repo:\n",
    "\n",
    "Simplified and tested template of a **sequential** CrewAI crew performing **web searches**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "PkwONSCBwAdO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title üë®‚Äçü¶Ø Run this cell to hide all warnings (optional)\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To avoid the restart session warning in Colab, exclude the PIL and\n",
    "# pydevd_plugins packages from being imported. This is fine because\n",
    "# we didn't execute the code in the kernel session afterward.\n",
    "\n",
    "# import sys\n",
    "# sys.modules.pop('PIL', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "P8iHNKCfk9Rv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
    "# @markdown  üîÑ Restart the session and rerun the cell **if Colab requires it**.\n",
    "\n",
    "# %pip install crewai_tools  --quiet\n",
    "# print(\"---\")\n",
    "# %pip show crewAI crewai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"asia-southeast1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "BhAt-unGk4kA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jupyter/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# @title üîë Input API Key by running this cell\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from textwrap import dedent\n",
    "\n",
    "# Check if the 'output-files' directory exists, and create it if it doesn't\n",
    "if not os.path.exists('output-files'):\n",
    "    os.makedirs('output-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "# from langchain_vertexai import ChatGemini\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import uuid, os\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name='gemini-1.5-pro-002', #\"gemini-1.0-pro-002\", # Replace with your desired Gemini model\n",
    "    project_id=os.getenv(PROJECT_ID), # Your Vertex AI project ID\n",
    "    location=\"us-central1\", # Your Vertex AI location\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "dvJMDhIoI2Iw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file downloaded and saved to: dataset/IMDB-Movie-Data.csv\n"
     ]
    }
   ],
   "source": [
    "# @title ‚¨áÔ∏è Download Sample .csv Dataset\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Specify the folder path where you want to save the file\n",
    "folder_path = 'dataset'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Sample .csv data from IMDB.com\n",
    "url = 'https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Specify the file path including the folder\n",
    "csv_file_path = os.path.join(folder_path, 'IMDB-Movie-Data.csv')\n",
    "\n",
    "with open(csv_file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"CSV file downloaded and saved to: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "IENZ1rmviDZY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting batches in chromadb: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:21<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# @title üßæ Instantiate `CSVSearchTool` with a `.csv` File\n",
    "\n",
    "# @markdown By default, the tool uses OpenAI for both embeddings and summarization.\n",
    "\n",
    "# @markdown To customize the model, you can use a config dictionary. See how [here](https://docs.crewai.com/tools/CSVSearchTool/#installation).\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import CSVSearchTool\n",
    "\n",
    "# Instantiate tools\n",
    "\n",
    "# This tool is used to perform a RAG (Retrieval-Augmented Generation) search within a CSV file's content.\n",
    "\n",
    "# Initialize the tool with a specific CSV file. This setup allows the agent to only search the given CSV file.\n",
    "\n",
    "csv_search_tool = CSVSearchTool(csv_file_path,     config=dict(\n",
    "        llm=dict(\n",
    "            provider=\"vertexai\", # or google, openai, anthropic, llama2, ...\n",
    "            config=dict(\n",
    "                model=\"gemini-pro\",\n",
    "                temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),           \n",
    "        embedder=dict(\n",
    "            provider=\"vertexai\",\n",
    "            config=dict(\n",
    "                model=\"textembedding-gecko\",\n",
    "                # task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# OR\n",
    "\n",
    "# Initialize the tool without a specific CSV file. Agent  will need to provide the CSV path at runtime.\n",
    "\n",
    "# tool = CSVSearchTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "In CrewAI, agents are autonomous entities designed to perform specific roles and achieve particular goals. Each agent uses a language model (LLM) and may have specialized tools to help execute tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "id": "hZJwUoXasrhx"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 88\u001b[0m\n\u001b[1;32m      8\u001b[0m agent_1 \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m      9\u001b[0m     role\u001b[38;5;241m=\u001b[39mdedent((\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m agent_2 \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     39\u001b[0m     role\u001b[38;5;241m=\u001b[39mdedent((\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m agent_3 \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     69\u001b[0m     role\u001b[38;5;241m=\u001b[39mdedent((\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m)), \u001b[38;5;66;03m# Think of this as the job title\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     backstory\u001b[38;5;241m=\u001b[39mdedent((\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m)), \u001b[38;5;66;03m# This is the backstory of the agent, this helps the agent to understand the context of the task\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     goal\u001b[38;5;241m=\u001b[39mdedent((\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m)), \u001b[38;5;66;03m# This is the goal that the agent is trying to achieve\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[csv_search_tool],\n\u001b[1;32m     82\u001b[0m     allow_delegation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# ‚Üë Whether the agent execution should be in verbose mode\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     max_rpm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;66;03m# This is the maximum number of requests per minute that the agent can make to the language model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[43mChatOpenAI\u001b[49m(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "# @title üïµüèª Define your agents\n",
    "\n",
    "# from langchain_groq import ChatGroq\n",
    "# ‚Üë Uncomment to use Groq's API\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# ‚Üë Uncomment to use Anthropic's API\n",
    "\n",
    "agent_1 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[csv_search_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=llm\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")\n",
    "\n",
    "agent_2 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[csv_search_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=llm\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")\n",
    "\n",
    "agent_3 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[csv_search_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=llm\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tasks\n",
    "Tasks in CrewAI are specific assignments given to agents, detailing the actions they need to perform to achieve a particular goal. Tasks can have dependencies and context, and can be executed asynchronously to ensure an efficient workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dqtn3w1qs-Bu"
   },
   "outputs": [],
   "source": [
    "# @title üìù Define your tasks\n",
    "\n",
    "import datetime\n",
    "\n",
    "task_1 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_1,\n",
    "    output_file=f'output-files/agent_1-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    "    # ‚Üë The output of each task iteration will be saved here\n",
    ")\n",
    "\n",
    "task_2 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_2,\n",
    "    context=[task_1],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    "    output_file=f'output-files/agent_2-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    "    # ‚Üë The output of each task iteration will be saved here\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_3,\n",
    "    context=[task_2],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    "    output_file=f'output-files/agent_3-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    "    # ‚Üë The output of each task iteration will be saved here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "HfJRdGHesMwn"
   },
   "outputs": [],
   "source": [
    "# @title ‚å®Ô∏è Define any variables you have and input them\n",
    "print(\"## Welcome to the YOUR_CREW_NAME\")\n",
    "print('-------------------------------------------')\n",
    "var_1 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_2 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_3 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nrBn8dMlxfCn"
   },
   "outputs": [],
   "source": [
    "# @title üöÄ Get your crew to work!\n",
    "def main():\n",
    "    # Instantiate your crew with a sequential process\n",
    "    crew = Crew(\n",
    "        agents=[agent_1, agent_2, agent_3],\n",
    "        tasks=[task_1, task_2, task_3],\n",
    "        verbose=True,  # You can set it to True or False\n",
    "        # ‚Üë indicates the verbosity level for logging during execution.\n",
    "        process=Process.sequential\n",
    "        # ‚Üë the process flow that the crew will follow (e.g., sequential, hierarchical).\n",
    "    )\n",
    "\n",
    "    inputs = {\n",
    "    \"var_1\": var_1,\n",
    "    \"var_2\": var_2,\n",
    "    \"var_3\": var_3\n",
    "    }\n",
    "\n",
    "    result = crew.kickoff(inputs=inputs)\n",
    "    print(\"\\n\\n########################\")\n",
    "    print(\"## Here is your custom crew run result:\")\n",
    "    print(\"########################\\n\")\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  result = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ty33sg3MxNZU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title üñ•Ô∏è Display the results of your crew as markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
    "\n",
    "# Display the markdown content\n",
    "display(Markdown(markdown_text))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
